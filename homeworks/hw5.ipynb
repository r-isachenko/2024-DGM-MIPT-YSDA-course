{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZXJoDiD_x-N"
   },
   "source": [
    "# Homework5: Denoising Diffusion Probabilistic Model (DDPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxF8ewFXn1HO"
   },
   "source": [
    "## Task 1: Theory (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sN6DycPP2Xq2"
   },
   "source": [
    "### Problem 1: Gaussian Diffusion (2pt)\n",
    "\n",
    "In the course we have discussed two types of gaussian diffusions:\n",
    "- $\\mathbf{x}_t = \\mathbf{x}_0 + \\sigma_t \\cdot \\boldsymbol{\\epsilon}$ - score-based models,\n",
    "- $\\mathbf{x}_t = \\sqrt{1 - \\beta_t} \\cdot \\mathbf{x}_{t-1} + \\sqrt{\\beta_t} \\cdot \\boldsymbol{\\epsilon}$ - diffusion models.\n",
    "\n",
    "One may ask, why we do not consider the more general diffusion models. It was the idea of the paper [Variational Diffusion Models](https://arxiv.org/abs/2107.00630).\n",
    "\n",
    "Let consider the diffusion of the form\n",
    "$$\n",
    "    \\mathbf{x}_t = \\alpha_t \\cdot \\mathbf{x}_0 + \\sigma_t \\cdot \\boldsymbol{\\epsilon}, \\quad \\mathbf{x}_t \\sim q(\\mathbf{x}_t | \\mathbf{x}_0) = \\mathcal{N}(\\alpha_t \\cdot \\mathbf{x}_0, \\sigma_t^2 \\cdot \\mathbf{I}).\n",
    "$$\n",
    "\n",
    "1) Prove that if we would like to to choose $\\alpha_t$ and $\\sigma_t$ such that the distribution of $\\mathbf{x}_{\\infty}$ has the identity covariance matrix, then it is necessary that\n",
    "$$\n",
    "a = \\sqrt{\\alpha}; \\quad b = \\sqrt{1 − \\alpha}.\n",
    "$$\n",
    "That is why the standard diffusion is called **Variance Preserving**.\n",
    "\n",
    "2) Find the distribution $q(\\mathbf{x}_t | \\mathbf{x}_s)$ for $s < t$ (you have to derive the formulas for mean $\\alpha_{t|s}$ and variance $\\sigma_{t|s}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbxPyzwcuinj"
   },
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Strided sampling (1pt)\n",
    "\n",
    "Sampling from DDPM is very slow.  There are several techniques to alleviate this drawback. \n",
    "In this task we are going to investigate one of them.\n",
    "\n",
    "Assume we have already trained a model $p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta})$ to \"reverse\" a Markov chain of length $T$.\n",
    "\n",
    "Let try to build inference process using subsequence of timesteps\n",
    "$\\{S_0 = 0, S_1, \\ldots, S_{T'-1}, S_{T'} = T\\}$, where $T' < T$.\n",
    "\n",
    "Using this subsequence we have to do $T'$ inference steps instead of $T$. It could dramatically reduce inference time.\n",
    "\n",
    "Find the expression for the iterative update in this case (how to get $\\mathbf{x}_{S_{t-1}}$ from $\\mathbf{x}_{S_t}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Conditioned reverse distribution for NCSN (1pt)\n",
    "\n",
    "In the DDPM model the distribution $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)$ played the crucial role.\n",
    "\n",
    "Find the parameters of this Normal distribution for the NCSN Markov chain $\\mathbf{x}_t = \\mathbf{x}_0 + \\sigma_t \\cdot \\boldsymbol{\\epsilon}$.\n",
    "\n",
    "**Note:** in this case the mean should be the convex combination of $\\mathbf{x}_t$ and $\\mathbf{x}_0$ (this differs from the DDPM Markov chain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "jppIpVyZ2Xq3",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "629ad74a-6fad-434d-b7e5-e19ae589f687"
   },
   "outputs": [],
   "source": [
    "COMMIT_HASH = \"11668881e2da2ea7938417bdabda0397660508c8\"\n",
    "!if [ -d dgm_utils ]; then rm -Rf dgm_utils; fi\n",
    "!git clone https://github.com/r-isachenko/dgm_utils.git\n",
    "%cd dgm_utils\n",
    "!git checkout {COMMIT_HASH}\n",
    "!pip install ./\n",
    "%cd ./..\n",
    "!rm -Rf dgm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Blg_otRk23ud"
   },
   "outputs": [],
   "source": [
    "from dgm_utils import train_model\n",
    "from dgm_utils import show_samples, visualize_images, load_dataset, visualize_2d_data, visualize_2d_samples\n",
    "from dgm_utils import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Snskjc-2_o4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    print('GPU found :)')\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print('GPU not found :(')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRFti0_GCRpD"
   },
   "source": [
    "## Task 2: DDPM on 2D data (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8vx6pxgCqBv"
   },
   "source": [
    "In this part you have to implement your own diffusion model (DDPM) and apply it to 2D dataset.\n",
    "\n",
    "Let's take a look at dataset samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3U4b0HQ2F06",
    "outputId": "a3d8dfdd-0e64-4f51-a1eb-c6346c7ca01c"
   },
   "outputs": [],
   "source": [
    "COUNT = 5000\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = load_dataset('moons', size=COUNT, with_targets=True)\n",
    "visualize_2d_data(train_data, test_data, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRqWAIRmQDQ8"
   },
   "source": [
    "Below you see the utility function, which broadcasts tensors. Look carefully at this code, we will use it in the majority of methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VwXNzi6fQZm"
   },
   "outputs": [],
   "source": [
    "def _extract_into_tensor(arr, indices, broadcast_shape):\n",
    "    \"\"\"\n",
    "    Extract values from a 1-D torch tensor for a batch of indices.\n",
    "    :param arr: 1-D torch tensor.\n",
    "    :param timesteps: a tensor of indices to extract from arr.\n",
    "    :param broadcast_shape: a larger shape of K dimensions with the batch\n",
    "                            dimension equal to the length of timesteps.\n",
    "    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\n",
    "    \"\"\"\n",
    "    assert len(arr.shape) == 1\n",
    "    res = arr.to(device=indices.device)[indices].float()\n",
    "    while len(res.shape) < len(broadcast_shape):\n",
    "        res = res[..., None]\n",
    "\n",
    "\n",
    "    return res.expand(broadcast_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JGW21W32F07"
   },
   "source": [
    "### Forward Diffusion\n",
    "\n",
    "Let start with forward diffusion.\n",
    "\n",
    "**Forward process** is defined as a posterior distribution $q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)$.\n",
    "\n",
    "It is a Markov chain, which consequently adds gaussian noise to a given object $\\mathbf{x}_0$.\n",
    "\n",
    "At every step of this process the gaussian noise is added with different magnitude, which is determined with a schedule of variances $\\{\\beta_1, ... \\beta_T\\}$.\n",
    "If this schedule is chosen properly and T goes to infinity (or is large enough), we will converge to pure noise $\\mathcal{N}(0, I)$.\n",
    "\n",
    "Markov chain is defined by:\n",
    "$$\n",
    " q(\\mathbf{x}_t | \\mathbf{x}_{t - 1}) = \\mathcal{N}(\\mathbf{x}_t | \\sqrt{1 - \\beta_t}\\mathbf{x}_{t - 1}, \\beta_t \\mathbf{I}), \\quad q(\\mathbf{x}_{1:T}|\\mathbf{x}_0) = \\prod_{t = 1}^T q(\\mathbf{x}_t | \\mathbf{x}_{t - 1})\n",
    "$$\n",
    "\n",
    "In order to get $\\mathbf{x}_t$ we have to compute $\\mathbf{x}_1, ..., \\mathbf{x}_{t - 1}$ iteratively.\n",
    "\n",
    "Hopefully, due to the properties of the gaussian distribution we can do it more efficiently.\n",
    "\n",
    "Let's denote\n",
    "$\\alpha_t = 1- \\beta_t$ и $\\bar{\\alpha}_t= \\prod_{s = 1}^t\\alpha_s$.\n",
    "Then\n",
    "$$\n",
    "q(\\mathbf{x}_t | \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t|\\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1-\\bar{\\alpha}_t) \\mathbf{I}).\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "Here we could get very useful expression\n",
    "$$\n",
    "    \\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1-\\bar{\\alpha}_t} \\cdot \\boldsymbol{\\epsilon}. \\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usjLZY1-2F07"
   },
   "source": [
    "Now we will create base class for diffusion (we will use it as a python base class for forward and backward diffusions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPgOkluQ2F07",
    "outputId": "bf60783a-31cc-4254-ec20-ca747ecd844f"
   },
   "outputs": [],
   "source": [
    "class BaseDiffusion:\n",
    "    def __init__(self, num_timesteps: int):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.betas = self._get_beta_schedule(num_timesteps)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_beta_schedule(num_diffusion_timesteps, s=0.008):\n",
    "        def f(t, T):\n",
    "            return (np.cos((t / T + s) / (1 + s) * np.pi / 2)) ** 2\n",
    "\n",
    "        alphas = []\n",
    "        f0 = f(0, num_diffusion_timesteps)\n",
    "\n",
    "        for t in range(num_diffusion_timesteps + 1):\n",
    "            alphas.append(f(t, num_diffusion_timesteps) / f0)\n",
    "\n",
    "        betas = []\n",
    "\n",
    "        for t in range(1, num_diffusion_timesteps + 1):\n",
    "            betas.append(min(1 - alphas[t] / alphas[t - 1], 0.999))\n",
    "\n",
    "        return torch.from_numpy(np.array(betas)).double()\n",
    "\n",
    "\n",
    "basediff = BaseDiffusion(num_timesteps=20)\n",
    "\n",
    "plt.plot(basediff.betas.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrGZqa5A2F07"
   },
   "source": [
    "We are ready to define forward diffusion process. It has 2 methods:\n",
    "- to get mean and variance of the distribution $q(\\mathbf{x}_t | \\mathbf{x}_0)$,\n",
    "- to get samples from this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3X5Gm1aC3zc"
   },
   "outputs": [],
   "source": [
    "class ForwardDiffusion(BaseDiffusion):\n",
    "    def get_mean_variance(self, x0, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # calculate mean and variance of the distribution q(x_t | x_0) (use equation (1))\n",
    "        # use _extract_into_tensor() function to get tensors of the same shape as x0\n",
    "        \n",
    "        # ====\n",
    "        return mean, variance\n",
    "\n",
    "    def get_samples(self, x0, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample from the distribution q(x_t | x_0) (use equation (2))\n",
    "        \n",
    "        # ====\n",
    "        return samples\n",
    "\n",
    "\n",
    "def test_forward_diffusion():\n",
    "    fdiff = ForwardDiffusion(num_timesteps=100)\n",
    "    SHAPE = [2, 20]\n",
    "    x0 = torch.ones(SHAPE)\n",
    "    t = torch.ones((2,)).long() * 5\n",
    "    mean, variance = fdiff.get_mean_variance(x0=x0, t=t)\n",
    "    assert list(mean.shape) == SHAPE\n",
    "    assert list(variance.shape) == SHAPE\n",
    "    assert np.allclose(mean.numpy(), np.ones(SHAPE) * 0.9944681)\n",
    "    assert np.allclose(variance.numpy(), np.ones(SHAPE) * 0.01103322)\n",
    "\n",
    "    xt = fdiff.get_samples(x0=x0, t=t)\n",
    "    assert list(xt.shape) == SHAPE\n",
    "\n",
    "    noise = torch.ones(SHAPE)\n",
    "    xt = fdiff.get_samples(x0=x0, t=t, noise=noise)\n",
    "    assert np.allclose(xt.numpy(), np.ones(SHAPE) * 1.0995072)\n",
    "\n",
    "\n",
    "test_forward_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDF9k0r32F07"
   },
   "source": [
    "Let visualize the forward diffusion process. Here you have to see how the distribution of the real samples transforms to the gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3hgwOcGfQZo",
    "outputId": "dfb27928-bf61-45e3-9453-fe1be2dacc18"
   },
   "outputs": [],
   "source": [
    "T = 100\n",
    "\n",
    "fdiff = ForwardDiffusion(num_timesteps=T)\n",
    "\n",
    "timestamps=[0, 2, 4, 10, 50]\n",
    "\n",
    "plot_n_steps = len(timestamps)\n",
    "for i, t in enumerate(timestamps):\n",
    "    x = fdiff.get_samples(x0=torch.from_numpy(train_data), t=torch.ones((train_data.shape[0], 1)).long() * t)\n",
    "    visualize_2d_samples(x, title=f\"Step of diffusion: {t}\", labels=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVEnKClW2F08"
   },
   "source": [
    "### Reverse Diffusion\n",
    "\n",
    "**Reverse process** consequently denoises pure gaussian noise $\\mathcal{N}(0, \\mathbf{I})$ until we do not get the object from the original distribution $\\pi(\\mathbf{x})$.\n",
    "\n",
    "It is a probability model with latent variables\n",
    "$p(\\mathbf{x}_0 | \\boldsymbol{\\theta}) := \\int p(\\mathbf{x}_{0:T} | \\boldsymbol{\\theta}) d\\mathbf{x}_{1:T}$,\n",
    "where\n",
    "- latents $\\mathbf{z} = \\{\\mathbf{x}_1, ..., \\mathbf{x}_T \\}$ correspond to noised objects\n",
    "- $\\mathbf{x}_0$ is an object from the original distribution $\\pi(\\mathbf{x})$.\n",
    "\n",
    "Joint distribution $p(\\mathbf{x}_{0:T} | \\boldsymbol{\\theta})$ is called reverse diffusion process, which is essentially a Markov chain of gaussian distributions $p(\\mathbf{x}_t|\\mathbf{x}_t, \\boldsymbol{\\theta})$:\n",
    "$$\n",
    "p(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod_{t = 1}^T p(\\mathbf{x}_{t-1}|\\mathbf{x}_t, \\boldsymbol{\\theta}), \\quad p(\\mathbf{x}_{T} | \\boldsymbol{\\theta})=\\mathcal{N}(0, \\mathbf{I})\n",
    "$$\n",
    "$$\n",
    "  p(\\mathbf{x}_{t - 1}|\\mathbf{x}_t | \\boldsymbol{\\theta}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t), \\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t)). \\tag{3}\n",
    "$$\n",
    "\n",
    "In Lecture 10 we have derived ELBO for this model:\n",
    "\n",
    "$$\n",
    "    \\mathcal{L}(q, \\boldsymbol{\\theta}) =  \\mathbf{E}_{q} \\Bigl[\\log p(\\mathbf{x}_0 | \\mathbf{x}_1, \\boldsymbol{\\theta}) - KL\\bigl(q(\\mathbf{x}_T | \\mathbf{x}_0) || p(\\mathbf{x}_T)\\bigr)\n",
    "    - \\sum_{t=2}^T \\underbrace{KL \\bigl(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) || p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta} )\\bigr)}_{\\mathcal{L}_t} \\Bigr].\n",
    "$$\n",
    "\n",
    "Here we use the following distribution $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) = \\mathcal{N}( \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0), \\tilde{\\beta}_t \\mathbf{I}) $, where\n",
    "$$\n",
    "\\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1 - \\bar{\\alpha}_t} \\mathbf{x}_0\n",
    "\\tag{4}\n",
    "$$\n",
    "$$\n",
    "\\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\cdot \\beta_t\n",
    "\\tag{5}\n",
    "$$\n",
    "\n",
    "(These scary formulas are not difficult to derive, follow the link to find details [Denoising Diffusion Probabilistic Models (Ho et al. 2020)](https://arxiv.org/abs/2006.11239)).\n",
    "\n",
    "Now our goal is to define parameters $\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t), \\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t)$ of reverse diffusion.\n",
    "\n",
    "#### Variance\n",
    "Our first assumption is to set the variance $\\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t) = \\tilde{\\beta}_t$. This is very native assumption\n",
    "\n",
    "#### Mean\n",
    "Here we will use the expression (2) to get $\\mathbf{x}_0$ from $\\mathbf{x}_t$:\n",
    "$$\n",
    "    \\mathbf{x}_0 = \\frac{\\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_{t}} \\cdot \\boldsymbol{\\epsilon}}{\\sqrt{\\bar{\\alpha}_{t}}}.\n",
    "    \\tag{6}\n",
    "$$\n",
    "\n",
    "If we put this expression to the formula (4) we will get:\n",
    "$$\n",
    "    \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\cdot \\boldsymbol{\\epsilon} \\right).\n",
    "$$\n",
    "\n",
    "So the idea here to parametrize the model mean in the same functional form:\n",
    "$$\n",
    "    \\boldsymbol{\\mu}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\cdot \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t) \\right).\n",
    "$$\n",
    "\n",
    "**Note:** our model will predict the noise which was applied to $\\mathbf{x}_0$ to get $\\mathbf{x}_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Imt4i-zM2F08",
    "outputId": "401299f2-230f-4d74-f085-b6acb266f34c"
   },
   "outputs": [],
   "source": [
    "class ReverseDiffusion(BaseDiffusion):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alphas_cumprod_prev = torch.cat(\n",
    "            [torch.tensor([1.0], device=self.betas.device), self.alphas_cumprod[:-1]], dim=0\n",
    "        )\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # calculate variance of the distribution q(x_{t-1} | x_t, x_0) (use equation (5))\n",
    "        \n",
    "        # ====\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # calculate coefficients of mean of the distribution q(x_{t-1} | x_t, x_0) (use equation (4))\n",
    "        # mean = x_coef * x_t + x0_coef * x_0\n",
    "        \n",
    "        # ====\n",
    "\n",
    "    def get_x0(self, xt, eps, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # get x_0 (use equation (6))\n",
    "        \n",
    "        # ====\n",
    "        return x0\n",
    "\n",
    "    def get_mean_variance(self, xt, eps, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # get mean and variance of the distribution q(x_{t-1} | x_t, x_0) (use equations (4) and (5))        \n",
    "        # use get_x0 method to get x_0\n",
    "\n",
    "        # ====\n",
    "        return mean, variance\n",
    "\n",
    "    def get_samples(self, xt, eps, t):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) get mean and variance of the distribution q(x_{t-1} | x_t, x_0)\n",
    "        # 2) sample noise from the standard normal \n",
    "        # 3) get samples using reparametrization trick\n",
    "        \n",
    "        # ====\n",
    "        return sample.float()\n",
    "\n",
    "\n",
    "def test_reverse_diffusion():\n",
    "    rdiff = ReverseDiffusion(num_timesteps=100)\n",
    "    SHAPE = [2, 20]\n",
    "    xt = torch.ones(SHAPE)\n",
    "    eps = torch.ones(SHAPE)\n",
    "    t = torch.ones((2,)).long() * 5\n",
    "\n",
    "    x0 = rdiff.get_x0(xt=xt, eps=eps, t=t)\n",
    "    assert list(x0.shape) == SHAPE\n",
    "    assert np.allclose(x0.numpy(), np.ones(SHAPE) * 0.8999391)\n",
    "\n",
    "    mean, variance = rdiff.get_mean_variance(xt=xt, eps=eps, t=t)\n",
    "    assert list(mean.shape) == SHAPE\n",
    "    assert list(variance.shape) == SHAPE\n",
    "    assert np.allclose(mean.numpy(), np.ones(SHAPE) * 0.9723116)\n",
    "    assert np.allclose(variance.numpy(), np.ones(SHAPE) * 0.00222036)\n",
    "\n",
    "    x = rdiff.get_samples(xt, eps, t)\n",
    "    assert list(x.shape) == SHAPE\n",
    "\n",
    "\n",
    "test_reverse_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJuBzzar2F08"
   },
   "source": [
    "### Model\n",
    "\n",
    "In this task we will use simple MLP model to parametrize distribution $p(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\boldsymbol{\\theta})$. It will be conditioned on the timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbtFK3NF2F08"
   },
   "outputs": [],
   "source": [
    "class ConditionalMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, num_embeds: int, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.x_proj = nn.Linear(input_dim, self.hidden_dim)\n",
    "        self.t_proj = nn.Embedding(num_embeds, self.hidden_dim)\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(self.hidden_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.x_proj(x)\n",
    "        t = self.t_proj(t.int())\n",
    "        x = x + t\n",
    "        x = F.selu(x)\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "def test_conditional_mlp():\n",
    "    SHAPE = [2, 20]\n",
    "    T = 100\n",
    "    x = torch.ones(SHAPE)\n",
    "    t = torch.ones((2,)).long() * 5\n",
    "    model = ConditionalMLP(input_dim=20, num_embeds=100)\n",
    "    output = model(x, t)\n",
    "    assert list(output.shape) == SHAPE\n",
    "\n",
    "\n",
    "test_conditional_mlp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCXBSZe32F09"
   },
   "source": [
    "### DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEZ__C82KlzL"
   },
   "source": [
    "Let return to the ELBO. The main part of it is:\n",
    "$$\n",
    "    \\mathcal{L}_t = KL \\bigl(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) || p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta} )\\bigr)\n",
    "$$\n",
    "\n",
    "In Lecture 10 we have got that\n",
    "$$\n",
    "    \\mathcal{L}_t = \\mathbf{E}_{\\boldsymbol{\\epsilon}} \\left[ \\frac{\\beta_t^2}{2 \\tilde{\\beta_t} \\alpha_t (1 - \\bar{\\alpha}_t)} \\| \\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t) \\|^2 \\right].\n",
    "$$\n",
    "\n",
    "In practice this loss is simplified. Particilarly, we will omit coefficient of the norm and we will sample index $t$ at each training step.\n",
    "\n",
    "Finally, we will train our model with the following objective:\n",
    "$$\n",
    "\\text{loss} = \\mathbf{E}_{\\mathbf{x}_0, \\boldsymbol{\\epsilon}, t}\\bigg[ \\|\\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}, t}(\\mathbf{x}_t)\\|^2\\bigg],\n",
    "$$\n",
    "where $\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\boldsymbol{\\epsilon}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqPzHQ_32F09"
   },
   "source": [
    "The following class implements two methods:\n",
    "- `loss` - to compute the loss at the training step;\n",
    "- `sample` - to sample from the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTy1kSEy2F09"
   },
   "outputs": [],
   "source": [
    "class DDPM(BaseModel):\n",
    "    def __init__(self, num_timesteps: int, model: nn.Module):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        self.forward_diffusion = ForwardDiffusion(num_timesteps=num_timesteps)\n",
    "        self.reverse_diffusion = ReverseDiffusion(num_timesteps=num_timesteps)\n",
    "        self.model = model\n",
    "        self.shape = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, num_samples: int):\n",
    "        assert self.shape is not None\n",
    "        x = torch.randn((num_samples, *self.shape), device=self.device, dtype=torch.float32)\n",
    "        indices = list(range(self.num_timesteps))[::-1]\n",
    "\n",
    "        for i in indices:\n",
    "            t = torch.tensor([i] * num_samples, device=x.device)\n",
    "            # ====\n",
    "            # your code\n",
    "            # 1) get epsilon from the model\n",
    "            # 2) sample from the reverse diffusion\n",
    "            \n",
    "            # ====\n",
    "        return x\n",
    "\n",
    "    def loss(self, x0):\n",
    "        if self.shape is None:\n",
    "            self.shape = list(x0.shape)[1:]\n",
    "        t = torch.randint(0, self.num_timesteps, size=(x0.size(0),), device=x0.device)\n",
    "        noise = torch.randn_like(x0)\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) get x_t\n",
    "        # 2) get epsilon from the model\n",
    "        # 3) compute mse loss between epsilon and noise\n",
    "        \n",
    "        # ====\n",
    "        loss = F.mse_loss(eps, noise)\n",
    "        return {\"total_loss\": loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw6vueDnTt7C"
   },
   "source": [
    "### Training\n",
    "\n",
    "Now we are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 100 # you can change it\n",
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "LR = \n",
    "EPOCHS = \n",
    "# ====\n",
    "\n",
    "model = ConditionalMLP(input_dim=2, num_embeds=T)\n",
    "ddpm = DDPM(num_timesteps=T, model=model)\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# try your own optimizer/scheduler\n",
    "optimizer = torch.optim.AdamW(ddpm.parameters(), lr=LR, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.995)\n",
    "\n",
    "train_model(\n",
    "    ddpm,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=DEVICE,\n",
    "    n_samples=1024,\n",
    "    visualize_samples=True,\n",
    "    logscale_y=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ijiAy6pUvkn"
   },
   "source": [
    "Now let's sample from our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ddpm.sample(num_samples=5000).cpu()\n",
    "\n",
    "visualize_2d_samples(samples, title=\"Samples\", s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RSpn0XJU_G9"
   },
   "source": [
    "Now let's see how denoising looks like (similarly to forward noising process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jXmq3s42F0-",
    "outputId": "56f3ee9e-b069-45ac-9690-4cda3fcf6716"
   },
   "outputs": [],
   "source": [
    "timestamps=[0, 2, 4, 10, 50]\n",
    "\n",
    "x = torch.randn(train_data.shape[0], 2, requires_grad=False).to(ddpm.device)\n",
    "for i in range(ddpm.num_timesteps - 1, -1, -1):\n",
    "    t = torch.tensor(i, dtype=torch.long, requires_grad=False).expand(x.shape[0]).to(ddpm.device)\n",
    "    with torch.no_grad():\n",
    "        eps = ddpm.model(x, t)\n",
    "        x = ddpm.reverse_diffusion.get_samples(xt=x, eps=eps, t=t)\n",
    "    if i in reversed(timestamps):\n",
    "        x_ = x.cpu()\n",
    "        visualize_2d_samples(x_, title=f\"Samples from timestamp: {i}\", s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXJnkzgiRGRo"
   },
   "source": [
    "## Task3: DDPM on MNIST (4pt)\n",
    "\n",
    "Let apply our diffusion model to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oktOew8b2F1F",
    "outputId": "a6fc21c2-6862-4c8b-d163-11e41db863be"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset(\"mnist\", flatten=False, binarize=False)\n",
    "visualize_images(train_data, \"MNIST samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFhOvS0PPZoe"
   },
   "source": [
    "Let's take a look at the forward process for the MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydfzM0RU2F1G",
    "outputId": "8317e111-ec29-4180-e7a5-c58207647a6e"
   },
   "outputs": [],
   "source": [
    "T = 1000\n",
    "\n",
    "fdiff = ForwardDiffusion(num_timesteps=T)\n",
    "\n",
    "timestamps=[0, 50, 100, 200, 300, 500, 600, 800, 999]\n",
    "\n",
    "plot_n_steps = len(timestamps)\n",
    "samples = []\n",
    "x0 = train_data[10:11]\n",
    "x0 = 2 * x0 - 1\n",
    "for i, t in enumerate(timestamps):\n",
    "    x = fdiff.get_samples(x0=torch.from_numpy(x0), t=torch.ones((x0.shape[0], 1)).long() * t)\n",
    "    samples.append(x.cpu().numpy())\n",
    "\n",
    "samples = np.concatenate(samples)\n",
    "samples = 0.5 * samples + 0.5\n",
    "show_samples(samples, title=\"Noisy samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10tMXiU8P_6v"
   },
   "source": [
    "The model is written for you. We will use conditioned ResNet architecture. But you could change it if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNyTMSl42F1G"
   },
   "outputs": [],
   "source": [
    "class ConditionedResnetBlock(nn.Module):\n",
    "    def __init__(self, dim: int, num_embeddings: int) -> None:\n",
    "        super().__init__()\n",
    "        # you could experiment with this architecture\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dim, dim, kernel_size=1),\n",
    "        )\n",
    "        self.dim = dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        time_embed = self.embedding(y).view(-1, self.dim, 1, 1)\n",
    "        return x + self.block(x + time_embed)\n",
    "\n",
    "\n",
    "class ConditionedSimpleResnet(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int, n_filters: int, n_blocks: int, num_embeddings: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # you could experiment with this architecture\n",
    "        self.first_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, n_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layers = nn.Sequential(*[ConditionedResnetBlock(n_filters, num_embeddings) for _ in range(n_blocks)])\n",
    "        self.last_block = nn.Sequential(\n",
    "            nn.ReLU(), nn.Conv2d(n_filters, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.n_filters = n_filters\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.first_block(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, t)\n",
    "        x = self.last_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_conditioned_resnet():\n",
    "    model = ConditionedSimpleResnet(in_channels=1, out_channels=1, n_filters=16, n_blocks=1, num_embeddings=2)\n",
    "    x = torch.rand((1, 1, 28, 28))\n",
    "    t = torch.zeros(size=(1,), dtype=torch.long)\n",
    "    out1 = model(x, t)\n",
    "    t = torch.ones(size=(1,), dtype=torch.long)\n",
    "    out2 = model(x, t)\n",
    "    assert not np.allclose(out1.detach().numpy(), out2.detach().numpy())\n",
    "\n",
    "\n",
    "test_conditioned_resnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we redefine two methods. Just to scale the data and clamp final samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMMNIST(DDPM):\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, num_samples: int):\n",
    "        x = super().sample(num_samples)\n",
    "        return torch.clamp(0.5 * x + 0.5, -1.0, 1.0)\n",
    "\n",
    "    def loss(self, x0):\n",
    "        x0 = 2.0 * x0 - 1.0\n",
    "        return super().loss(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V9Xv5wV2F1G"
   },
   "source": [
    "That is all. We are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNvEMcANjpMk",
    "outputId": "f1234402-9298-4b2a-a445-13894a817ccb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 1000\n",
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE = \n",
    "LR = \n",
    "WEIGHT_DECAY = \n",
    "EPOCHS = \n",
    "N_FILTERS = \n",
    "N_BLOCKS = \n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model_mnist = ConditionedSimpleResnet(in_channels=1, out_channels=1, n_filters=N_FILTERS, n_blocks=N_BLOCKS, num_embeddings=T)\n",
    "ddpm_mnist = DDPMMNIST(num_timesteps=T, model=model_mnist)\n",
    "\n",
    "# try your own optimizer/scheduler\n",
    "optimizer = torch.optim.Adam(ddpm_mnist.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# train\n",
    "train_model(\n",
    "    ddpm_mnist,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    n_samples=16,\n",
    "    visualize_samples=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4foGURhyRAaG"
   },
   "source": [
    "Let's draw samples from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10167,
     "status": "ok",
     "timestamp": 1699721305095,
     "user": {
      "displayName": "Роман Исаченко",
      "userId": "08996523319375397632"
     },
     "user_tz": -180
    },
    "id": "j89yASABkOve",
    "outputId": "3acb8522-1f90-46f1-e13c-02d1ef4ba68f"
   },
   "outputs": [],
   "source": [
    "ddpm_mnist = ddpm_mnist.to(DEVICE)\n",
    "samples = ddpm_mnist.sample(num_samples=25).cpu().numpy()\n",
    "\n",
    "show_samples(samples, title=\"Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1419c6699da14696a4dfcfa27645cbca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e2b4a42fa06484685e6dbbb718dd906",
      "placeholder": "​",
      "style": "IPY_MODEL_4bcd480b39ed49ef9fe7b619dac807b8",
      "value": " 10/10 [06:45&lt;00:00, 40.63s/it]"
     }
    },
    "24023cb9b33a47d79482e22c0d78c59f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "344606256fe7408981e4b7c28f17f3ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42e391bd46eb45f08aec7176554e039a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4bcd480b39ed49ef9fe7b619dac807b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "520e625662814b2f99edc701c9903cd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6abe89cddbba4ad0a838389391559646": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24023cb9b33a47d79482e22c0d78c59f",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_42e391bd46eb45f08aec7176554e039a",
      "value": 10
     }
    },
    "8e2b4a42fa06484685e6dbbb718dd906": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b19b8e868107423d8af000da1d7a0883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed0a4216cd004a9c9ab730676c43d3f2",
       "IPY_MODEL_6abe89cddbba4ad0a838389391559646",
       "IPY_MODEL_1419c6699da14696a4dfcfa27645cbca"
      ],
      "layout": "IPY_MODEL_ee741df5e91a40bba1e091ab4ddae28f"
     }
    },
    "ed0a4216cd004a9c9ab730676c43d3f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_344606256fe7408981e4b7c28f17f3ca",
      "placeholder": "​",
      "style": "IPY_MODEL_520e625662814b2f99edc701c9903cd9",
      "value": "100%"
     }
    },
    "ee741df5e91a40bba1e091ab4ddae28f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
