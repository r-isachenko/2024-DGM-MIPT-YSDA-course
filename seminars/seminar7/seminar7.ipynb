{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d99065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as TD\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "    GPU_DEVICE = 1\n",
    "    torch.cuda.set_device(GPU_DEVICE)\n",
    "else:\n",
    "    DEVICE='cpu'\n",
    "# DEVICE='cpu'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# dgm_utils\n",
    "from dgm_utils import train_model, show_samples, visualize_images\n",
    "from dgm_utils import visualize_2d_samples, visualize_2d_densities, visualize_2d_data\n",
    "\n",
    "def reset_seed():\n",
    "    OUTPUT_SEED = 0xBADBEEF\n",
    "    torch.manual_seed(OUTPUT_SEED)\n",
    "    np.random.seed(OUTPUT_SEED)\n",
    "\n",
    "reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d663c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from WGAN import WGAN, WGAN_GP, VanillaGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d1be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_model(hiddens):\n",
    "    assert len(hiddens) > 1\n",
    "\n",
    "    modules = []\n",
    "    for in_, out_ in zip(hiddens[:-2], hiddens[1:-1]):\n",
    "        modules.extend([nn.Linear(in_, out_), nn.ReLU()])\n",
    "\n",
    "    modules.append(nn.Linear(hiddens[-2], hiddens[-1]))\n",
    "\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "def plot_gan_data(data_fn, noise_fn, data_pdf=None):\n",
    "    noise = noise_fn(5000).numpy().flatten()\n",
    "    target = data_fn(5000).numpy().flatten()\n",
    "\n",
    "    plt.hist(noise, label='noise', alpha=0.5, density=True, color='b')\n",
    "    plt.hist(target, label='target', alpha=0.5, density=True, color='g')\n",
    "    if data_pdf is not None:\n",
    "        x = np.linspace(-6,6,100)\n",
    "        plt.plot(x, data_pdf(x), 'g', label='real distibution')\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_GAN(gan, data_pdf=None):\n",
    "    size = 500\n",
    "    x = np.linspace(-6,6,100)\n",
    "    bins = np.linspace(-6,6,60)\n",
    "    real_data = gan.data_fn(size)\n",
    "    noise = gan.noise_fn(size)\n",
    "    sampled_data = gan.generate_samples(noise)\n",
    "    \n",
    "    plt.hist(noise.numpy(), label='noise', alpha=0.5, density=True, color='b', bins=bins)\n",
    "    plt.hist(real_data.numpy(), label='real data', alpha=0.5, density=True, color='g', bins=bins)\n",
    "    plt.hist(sampled_data.numpy(), label='G samples', alpha=0.5, density=True, color='r', bins=bins)\n",
    "    \n",
    "    if data_pdf is not None:\n",
    "        plt.plot(x, data_pdf(x), 'g', label='real distibution')\n",
    "    with torch.no_grad():\n",
    "        plt.plot(x, gan.D(torch.from_numpy(x).float().unsqueeze(-1)).numpy(), 'b', label='D distibution')\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e438be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e34f6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d\n",
    "from seminar7_utils import make_inference, visualize_GAN_output, FullyConnectedMLP\n",
    "from WGAN import train_wgan, WGAN_MLPCritic\n",
    "from wgan_gp import train_wgan_gp\n",
    "\n",
    "def plot_losses(losses, title):\n",
    "    n_itr = len(losses)\n",
    "    xs = np.arange(n_itr)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(xs, losses)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel('Iterations', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d6d15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPGenerator(FullyConnectedMLP):\n",
    "\n",
    "    def sample(self, n):\n",
    "        z = torch.randn(size=(n, self.input_dim)).to(\n",
    "            next(iter(self.parameters())))\n",
    "        return self.forward(z)\n",
    "    \n",
    "    \n",
    "class WGAN_MLPGenerator(MLPGenerator):\n",
    "    pass\n",
    "\n",
    "\n",
    "class WGANGP_MLPGenerator(MLPGenerator):\n",
    "    pass\n",
    "\n",
    "\n",
    "class WGANGP_MLPCritic(FullyConnectedMLP):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d2159c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Deep Generative Models</center>\n",
    "## <center>Seminar 7</center>\n",
    "\n",
    "<center>22.10.2024</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6d699",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "Wasserstein GANs\n",
    "     \n",
    "     - Vanilla GAN\n",
    "     \n",
    "     - WGAN\n",
    "     \n",
    "     - WGAN-GP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a463465f",
   "metadata": {},
   "source": [
    "# Vanilla GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc9366",
   "metadata": {},
   "source": [
    "<img src=\"pics/gan_objective.jpg\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4aa9f0",
   "metadata": {},
   "source": [
    "**Practical Note**:\n",
    "\n",
    "Use **RMSProp** or **Adam** with $\\beta_1 = 0$ when training your GAN. Large $\\beta_1$ of Adam leads to training instabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff41728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 2\n",
    "noise_fn = lambda x: torch.rand((x, 1), device='cpu')-2\n",
    "data_fn = lambda x: mu+torch.randn((x, 1), device='cpu')\n",
    "data_pdf = lambda X: norm.pdf(X-mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc80eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gan_data(data_fn, noise_fn, data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b26f3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_hiddens = [1,64,64,1]\n",
    "dis_hiddens = [1,64,64,1]\n",
    "G = get_simple_model(gen_hiddens)\n",
    "D = nn.Sequential(*get_simple_model(dis_hiddens), nn.Sigmoid())\n",
    "\n",
    "gan = VanillaGAN(G, D, noise_fn, data_fn, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf05352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 30\n",
    "loss_g, loss_d_real, loss_d_fake = [], [], []\n",
    "start = time()\n",
    "for epoch in range(epochs):\n",
    "    #break\n",
    "    loss_g_running, loss_d_real_running, loss_d_fake_running = 0, 0, 0\n",
    "    for i,batch in enumerate(range(batches)):\n",
    "        lg_, (ldr_, ldf_) = gan.train_step()\n",
    "        #ldr_, ldf_ = gan.train_step_D()\n",
    "        #if i%step_size == 0:\n",
    "        #    print(i)\n",
    "        #    print('D train step')\n",
    "        #    visualize_GAN(gan)\n",
    "        #lg_ = gan.train_step_G()\n",
    "        #if i%step_size == 0:\n",
    "        #    print('G train step')\n",
    "        #    visualize_GAN(gan)\n",
    "        \n",
    "        loss_g_running += lg_\n",
    "        loss_d_real_running += ldr_\n",
    "        loss_d_fake_running += ldf_\n",
    "    loss_g.append(loss_g_running / batches)\n",
    "    loss_d_real.append(loss_d_real_running / batches)\n",
    "    loss_d_fake.append(loss_d_fake_running / batches)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} ({int(time() - start)}s):\"\n",
    "          f\" G={loss_g[-1]:.3f},\"\n",
    "          f\" Dr={loss_d_real[-1]:.3f},\"\n",
    "          f\" Df={loss_d_fake[-1]:.3f}\")\n",
    "    visualize_GAN(gan, data_pdf=data_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad7f9ff",
   "metadata": {},
   "source": [
    "## WGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff46d1",
   "metadata": {},
   "source": [
    "<img src=\"pics/WD.jpg\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0b24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb5ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d1c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c8f676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d779a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242467b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08081c1e",
   "metadata": {},
   "source": [
    "<img src=\"pics/KRD.jpg\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48eb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7ce8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ae9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e48fc3a",
   "metadata": {},
   "source": [
    "[WGAN](https://arxiv.org/abs/1701.07875) model uses weight clipping to enforce Lipschitzness of the critic.\n",
    "\n",
    "The model objective is\n",
    "$$\n",
    "\\min_{G} W(\\pi || p) \\approx \\min_{G} \\max_{\\boldsymbol{\\phi} \\in \\boldsymbol{\\Phi}} \\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} f(\\mathbf{x}, \\boldsymbol{\\phi})  - \\mathbb{E}_{p(\\mathbf{z})} f(G(\\mathbf{z}, \\boldsymbol{\\theta}), \\boldsymbol{\\phi} )\\right].\n",
    "$$\n",
    "Here $f(\\mathbf{x}, \\boldsymbol{\\phi})$ is the critic model. The critic weights $\\boldsymbol{\\phi}$ should lie in the compact set $\\boldsymbol{\\Phi} = [-c, c]^d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34180dc6",
   "metadata": {},
   "source": [
    "<img src=\"pics/wgan_alg.jpg\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110f468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 2\n",
    "noise_fn = lambda x: torch.rand((x, 1), device='cpu')-2\n",
    "data_fn = lambda x: mu+torch.randn((x, 1), device='cpu')\n",
    "data_pdf = lambda X: norm.pdf(X-mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3335a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_hiddens = [1,64,64,1]\n",
    "dis_hiddens = [1,64,64,1]\n",
    "G = get_simple_model(gen_hiddens)\n",
    "D = get_simple_model(dis_hiddens)\n",
    "\n",
    "gan = WGAN(G, D, noise_fn, data_fn, device='cpu', n_critic=5, clip_c=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_GAN(gan, data_pdf=data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eab924e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948900f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_g, loss_d_real, loss_d_fake, loss_WD = [], [], [], []\n",
    "start = time()\n",
    "for epoch in range(epochs):\n",
    "    #break\n",
    "    loss_g_running, loss_d_real_running, loss_d_fake_running, loss_WD_running = 0, 0, 0, 0\n",
    "    for i,batch in enumerate(range(batches)):\n",
    "        lg_, (ldr_, ldf_) = gan.train_step()\n",
    "        loss_g_running += lg_\n",
    "        loss_d_real_running += ldr_\n",
    "        loss_d_fake_running += ldf_\n",
    "        loss_WD_running = ldr_ - ldf_\n",
    "        \n",
    "    loss_g.append(loss_g_running / batches)\n",
    "    loss_d_real.append(loss_d_real_running / batches)\n",
    "    loss_d_fake.append(loss_d_fake_running / batches)\n",
    "    loss_WD.append(loss_WD_running / batches)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} ({int(time() - start)}s):\"\n",
    "          f\" G={loss_g[-1]:.3f},\"\n",
    "          f\" Dr={loss_d_real[-1]:.3f},\"\n",
    "          f\" Df={loss_d_fake[-1]:.3f},\"\n",
    "            f\" WD={loss_WD[-1]:.3f}\")\n",
    "    visualize_GAN(gan, data_pdf=data_pdf)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cb9b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for param in gan.D.parameters():\n",
    "    params.extend(param.detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475acde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(params, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfef2f7",
   "metadata": {},
   "source": [
    "### Bimodal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ded01c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_fn = lambda x: torch.rand((x, 1), device='cpu') - 0.5\n",
    "\n",
    "pi = torch.tensor([0.7, 0.3])\n",
    "mu = torch.tensor([-3., 3.])\n",
    "scale = torch.tensor([1., 1.])\n",
    "\n",
    "mixture_gaussian = TD.MixtureSameFamily(TD.Categorical(pi), TD.Normal(mu, scale))\n",
    "\n",
    "def data_fn(x):\n",
    "    return mixture_gaussian.sample((x, 1))\n",
    "\n",
    "def data_pdf(x):\n",
    "    return mixture_gaussian.log_prob(torch.tensor(x)).exp().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f74b69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_hiddens = [1,64,64,1]\n",
    "dis_hiddens = [1,64,64,1]\n",
    "G = get_simple_model(gen_hiddens)\n",
    "D = get_simple_model(dis_hiddens)\n",
    "\n",
    "gan = WGAN(G, D, noise_fn, data_fn, device='cpu', n_critic=5, clip_c=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_GAN(gan, data_pdf=data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442bcbcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_g, loss_d_real, loss_d_fake, loss_WD = [], [], [], []\n",
    "start = time()\n",
    "for epoch in range(epochs):\n",
    "    #break\n",
    "    loss_g_running, loss_d_real_running, loss_d_fake_running, loss_WD_running = 0, 0, 0, 0\n",
    "    for i,batch in enumerate(range(batches)):\n",
    "        lg_, (ldr_, ldf_) = gan.train_step()\n",
    "        loss_g_running += lg_\n",
    "        loss_d_real_running += ldr_\n",
    "        loss_d_fake_running += ldf_\n",
    "        loss_WD_running = ldr_ - ldf_\n",
    "        \n",
    "    loss_g.append(loss_g_running / batches)\n",
    "    loss_d_real.append(loss_d_real_running / batches)\n",
    "    loss_d_fake.append(loss_d_fake_running / batches)\n",
    "    loss_WD.append(loss_WD_running / batches)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} ({int(time() - start)}s):\"\n",
    "          f\" G={loss_g[-1]:.3f},\"\n",
    "          f\" Dr={loss_d_real[-1]:.3f},\"\n",
    "          f\" Df={loss_d_fake[-1]:.3f},\"\n",
    "            f\" WD={loss_WD[-1]:.3f}\")\n",
    "    visualize_GAN(gan, data_pdf=data_pdf)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c6189",
   "metadata": {},
   "source": [
    "### 2D WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46e95e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_data(size, var=0.02):\n",
    "    scale = 2\n",
    "    centers = [\n",
    "        (1, 0),\n",
    "        (-1, 0),\n",
    "        (0, 1),\n",
    "        (0, -1),\n",
    "        (1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
    "        (1. / np.sqrt(2), -1. / np.sqrt(2)),\n",
    "        (-1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
    "        (-1. / np.sqrt(2), -1. / np.sqrt(2))\n",
    "    ]\n",
    "\n",
    "    centers = [(scale * x, scale * y) for x, y in centers]\n",
    "    dataset = []\n",
    "\n",
    "    for i in range(size):\n",
    "        point = np.random.randn(2) * var\n",
    "        center = centers[np.random.choice(np.arange(len(centers)))]\n",
    "        point[0] += center[0]\n",
    "        point[1] += center[1]\n",
    "        dataset.append(point)\n",
    "\n",
    "    dataset = np.array(dataset, dtype='float32')\n",
    "    dataset /= 1.414  # stdev\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d571ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "COUNT = 20000\n",
    "\n",
    "train_data = generate_2d_data(COUNT, var=0.08) # 0.02, 0.1, 0.4\n",
    "visualize_2d_samples(train_data, \"Train data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084cc64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CRITIC_STEPS = 5 => more or less learning\n",
    "# CRITIC_STEPS = 1 => no learning\n",
    "\n",
    "reset_seed()\n",
    "BATCH_SIZE = 1024 # any adequate value\n",
    "GEN_HIDDENS = [32, 128, 128, 32] # 4 layers with < 128 neurons would be enough\n",
    "DISCR_HIDDENS = [64, 256, 256, 64] # 4 layers with < 128 neurons would be enough\n",
    "CRITIC_STEPS = 5 # > 2\n",
    "LR = 2e-4 # < 1e-2\n",
    "CLIP_C = 0.05 # < 1\n",
    "\n",
    "N_EPOCHS = 600 # change it if you want\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = WGAN_MLPGenerator(16, GEN_HIDDENS, 2).to(DEVICE)\n",
    "critic = WGAN_MLPCritic(2, DISCR_HIDDENS, 1).to(DEVICE)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    clip_c=CLIP_C,\n",
    "    visualize_steps=50,\n",
    "    use_cuda = DEVICE != 'cpu'\n",
    ")\n",
    "\n",
    "plot_losses(train_losses['discriminator_losses'], 'Critic loss')\n",
    "plot_losses(train_losses['generator_losses'], 'Generator loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd557717",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, grid, critic_output, critic_grad_norms = make_inference(generator, critic)\n",
    "visualize_GAN_output(samples, train_data, grid, critic_output, critic_grad_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9603f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for param in critic.parameters():\n",
    "    params.extend(param.detach().cpu().numpy().flatten())\n",
    "plt.hist(params, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f200e3a",
   "metadata": {},
   "source": [
    "## WGAN-GP\n",
    "\n",
    "[WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf)  model uses gradient penalty to enforce Lipschitzness.\n",
    "\n",
    "The model objective is\n",
    "$$\n",
    "    W(\\pi || p) = \\underbrace{\\mathbb{E}_{\\pi(\\mathbf{x})} f(\\mathbf{x})  - \\mathbb{E}_{p(\\mathbf{x} | \\boldsymbol{\\theta})} f(\\mathbf{x})}_{\\text{original critic loss}} + \\lambda \\underbrace{\\mathbb{E}_{U[0, 1]} \\left[ \\left( \\| \\nabla_{\\hat{\\mathbf{x}}} f(\\hat{\\mathbf{x}}) \\|_2 - 1 \\right) ^ 2\\right]}_{\\text{gradient penalty}},\n",
    "$$\n",
    "where the samples $\\hat{\\mathbf{x}}_t = t \\mathbf{x} + (1 - t) \\mathbf{y}$ with $t \\in [0, 1]$ are uniformly sampled along straight lines between pairs of points: $\\mathbf{x}$ from the data distribution $\\pi(\\mathbf{x})$ and $\\mathbf{y}$ from the generator distribution $p(\\mathbf{x} | \\boldsymbol{\\theta}))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c5e0d",
   "metadata": {},
   "source": [
    "<img src=\"pics/WGAN-GP_theorem.jpg\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383b07ef",
   "metadata": {},
   "source": [
    "<img src=\"pics/wgan-gp_alg.jpg\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2284748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 2\n",
    "noise_fn = lambda x: torch.rand((x, 1), device='cpu')-2\n",
    "data_fn = lambda x: mu+torch.randn((x, 1), device='cpu')\n",
    "data_pdf = lambda X: norm.pdf(X-mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8aeb133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_hiddens = [1,64,64,1]\n",
    "dis_hiddens = [1,64,64,1]\n",
    "G = get_simple_model(gen_hiddens)\n",
    "D = get_simple_model(dis_hiddens)\n",
    "\n",
    "gan = WGAN_GP(G, D, noise_fn, data_fn, device='cpu', n_critic=5, Lambda=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f57b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_GAN(gan, data_pdf=data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23de8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e05618",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step_size = 30\n",
    "loss_g, loss_d_real, loss_d_fake, loss_WD, loss_gp = [], [], [], [], []\n",
    "start = time()\n",
    "for epoch in range(epochs):\n",
    "    #break\n",
    "    loss_g_running, loss_d_real_running, loss_d_fake_running, loss_WD_running, loss_gp_running = 0, 0, 0, 0, 0\n",
    "    for i,batch in enumerate(range(batches)):\n",
    "        lg_, (ldr_, ldf_, lgp_) = gan.train_step()\n",
    "        #ldr_, ldf_ = gan.train_step_D()\n",
    "        #if i%step_size == 0:\n",
    "        #    print(i)\n",
    "        #    print('D train step')\n",
    "        #    visualize_GAN(gan)\n",
    "        #lg_ = gan.train_step_G()\n",
    "        #if i%step_size == 0:\n",
    "        #    print('G train step')\n",
    "        #    visualize_GAN(gan)\n",
    "        \n",
    "        loss_g_running += lg_\n",
    "        loss_d_real_running += ldr_\n",
    "        loss_d_fake_running += ldf_\n",
    "        loss_gp_running += lgp_\n",
    "        loss_WD_running = ldr_ - ldf_\n",
    "        \n",
    "    loss_g.append(loss_g_running / batches)\n",
    "    loss_d_real.append(loss_d_real_running / batches)\n",
    "    loss_d_fake.append(loss_d_fake_running / batches)\n",
    "    loss_gp.append(loss_gp_running / batches)\n",
    "    loss_WD.append(loss_WD_running / batches)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} ({int(time() - start)}s):\"\n",
    "          f\" G={loss_g[-1]:.3f},\"\n",
    "          f\" Dr={loss_d_real[-1]:.3f},\"\n",
    "          f\" Df={loss_d_fake[-1]:.3f}\"\n",
    "          f\" WD={loss_WD[-1]:.3f},\"\n",
    "          f\" GP={loss_gp[-1]:.3f}\")\n",
    "    visualize_GAN(gan, data_pdf=data_pdf)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2dbeb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "BATCH_SIZE = 1024 # any adequate value\n",
    "GEN_HIDDENS = [32, 128, 128, 32] # 4 layers with < 128 neurons would be enough\n",
    "DISCR_HIDDENS = [64, 256, 256, 64] # 4 layers with < 128 neurons would be enough\n",
    "CRITIC_STEPS = 5 # > 2\n",
    "LR = 2e-4 # < 1e-2\n",
    "GP_WEIGHT = 10 # > 5\n",
    "\n",
    "N_EPOCHS = 800 # change it if you want\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = WGANGP_MLPGenerator(16, GEN_HIDDENS, 2).to(DEVICE)\n",
    "critic = WGANGP_MLPCritic(2, DISCR_HIDDENS, 1).to(DEVICE)\n",
    "\n",
    "train_losses = train_wgan_gp(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    gp_weight=GP_WEIGHT,\n",
    "    visualize_steps=50,\n",
    "    use_cuda = DEVICE != 'cpu'\n",
    ")\n",
    "\n",
    "plot_losses(train_losses['discriminator_losses'], 'Critic loss')\n",
    "plot_losses(train_losses['generator_losses'], 'Generator loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35986a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, grid, critic_output, critic_grad_norms = make_inference(generator, critic)\n",
    "visualize_GAN_output(samples, train_data, grid, critic_output, critic_grad_norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c483835a",
   "metadata": {},
   "source": [
    "## WGAN / WGAN-GP Recap\n",
    "\n",
    "1. **Lipschitz Condition for the Critic**\n",
    "   - Required by the **Kantorovich-Rubinstein duality** for Wasserstein Distance (WD).\n",
    "   - **Key difference**: No weight clipping for the generator!\n",
    "\n",
    "\n",
    "2. **Important Insights**:\n",
    "   - **KL & JSD Divergences fail** where WD succeeds (e.g., two parallel lines example).\n",
    "   - **Weaker topology**: Convergence in JS implies convergence in WD (WD is easier to optimize).\n",
    "   - Lipschitz continuity is essential for the criticâ€”achieved through **weight clipping**.\n",
    "   - **Loss correlates with visual quality** of the generated images.\n",
    "\n",
    "\n",
    "3. **Problems with Clipping**:\n",
    "   - **Weight sticking to boundaries** causes exploding or vanishing gradients.\n",
    "   - Refer to the visual example from the WGAN-GP paper.\n",
    "\n",
    "\n",
    "4. **WGAN-GP: More Robust**\n",
    "   - Gradient norm between real and generated samples is forced to be **1**.\n",
    "   - **No weight clipping** for the critic in WGAN-GP.\n",
    "\n",
    "\n",
    "5. **Why no oscillations (\"steps\") as in Vanilla GAN?**\n",
    "   - Thanks to the Lipschitz condition, training is smoother.\n",
    "\n",
    "\n",
    "6. **WGAN-GP Theorem Illustration**:\n",
    "   - The gradient norm between real and fake samples remains strictly **1** (e.g., set \\(\\lambda = 100\\))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfce565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656dd711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71bc65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "156f70be",
   "metadata": {},
   "source": [
    "## Bonus Chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04294403",
   "metadata": {},
   "source": [
    "### SNGAN\n",
    "\n",
    "Spectral Normalization GAN [article](https://arxiv.org/pdf/1802.05957.pdf) replaces the weights in the critic $f(\\mathbf{x}, \\boldsymbol{\\phi})$ by \n",
    "$$\n",
    "    \\mathbf{W}^{SN} = \\frac{\\mathbf{W}}{\\|\\mathbf{W}\\|_2}.\n",
    "$$\n",
    "\n",
    "This ensures that $\\| f\\|_L \\leq 1.$.\n",
    "\n",
    "Power iteration method allows to efficiently compute $\\| \\mathbf{W} \\|_2 = \\sqrt{\\lambda_{\\text{max}}(\\mathbf{W}^T \\mathbf{W})}$.\n",
    "    \n",
    "The pseudocode of the method is:\n",
    "* $\\mathbf{u}_0$ -- random vector.\n",
    "* for $k = 0, \\dots, n - 1$: \n",
    "$$\n",
    "    \\mathbf{v}_{k+1} = \\frac{\\mathbf{W}^T \\mathbf{u}_{k}}{\\| \\mathbf{W}^T \\mathbf{u}_{k} \\|}, \\quad \\mathbf{u}_{k+1} = \\frac{\\mathbf{W} \\mathbf{v}_{k+1}}{\\| \\mathbf{W} \\mathbf{v}_{k+1} \\|}.\n",
    "$$\n",
    "* approximate the spectral norm\n",
    "$$\n",
    "    \\| \\mathbf{W} \\|_2 = \\sqrt{\\lambda_{\\text{max}}(\\mathbf{W}^T \\mathbf{W})} \\approx \\mathbf{u}_{n}^T \\mathbf{W} \\mathbf{v}_{n}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394c4df",
   "metadata": {},
   "source": [
    "## GANs zoo\n",
    "\n",
    "### Losses\n",
    "\n",
    "- Vanilla GAN\n",
    "\n",
    "    <img src=\"pics/gan_objective.jpg\" width=800 height=800 />\n",
    "\n",
    "    - Nonsaturating Vanilla GAN\n",
    "\n",
    "- Wassersteing GAN \n",
    "\n",
    "    <img src=\"pics/WGAN_obj.jpg\" width=800 height=800 />\n",
    "    \n",
    "    - WGAN-GP\n",
    "\n",
    "- IPM GAN \n",
    "\n",
    "    **IPM** (Integral Probability Metric):\n",
    "    \n",
    "    $$\n",
    "    \\gamma_{\\mathcal{F}}(\\mathbb{P}, \\mathbb{Q}) = \\sup\\limits_{f \\in \\mathcal{F}} \\left\\vert \\int f d \\mathbb{P} - \\int f d \\mathbb{Q} \\right\\vert,\n",
    "    $$ \n",
    "    see [Sriperumbudur et. al.](https://arxiv.org/pdf/0901.2698.pdf) for the details on IPM metric.\n",
    "    \n",
    "    see [Mroueh et. al.](https://arxiv.org/pdf/1711.04894.pdf) for the examples of IPM GANs.\n",
    "    \n",
    "    \n",
    "- GAN with Hinge loss\n",
    "\n",
    "    <img src=\"pics/hinge_loss_GAN.png\" width=800 height=800 />\n",
    "    \n",
    "    see [Lim et. al.](https://arxiv.org/pdf/1705.02894.pdf)\n",
    "\n",
    "- fGAN \n",
    "\n",
    "    <img src=\"pics/fgan_loss.png\" width=800 height=800 />\n",
    "    \n",
    "    article: [Nowozin et. al.](https://arxiv.org/pdf/1606.00709.pdf)\n",
    "    \n",
    "    * **Question:** By which parameter we maximize, and by which we minimize?\n",
    "    \n",
    "- ...\n",
    "\n",
    "### Regularizations\n",
    "\n",
    "- Weight clipping, Gradient penalty in WGAN\n",
    "\n",
    "- Spectral Normalization (for general GAN architectures)\n",
    "\n",
    "- $R_1$, $R_2$, $R_3$ regularizations (penalize discriminator gradients) [paper](https://arxiv.org/pdf/1801.04406.pdf), [paper2](https://arxiv.org/pdf/1705.09367.pdf)\n",
    "\n",
    "- Improved techniques for training GANs [paper](https://arxiv.org/pdf/1606.03498.pdf)\n",
    "\n",
    "- Orthogonal regularization [paper](https://arxiv.org/pdf/1809.11096.pdf)\n",
    "\n",
    "    <img src=\"pics/ortho_reg.png\" width=400 height=800 />\n",
    "\n",
    "- ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
