{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae33adba",
   "metadata": {},
   "source": [
    "## Gaussian Autoregressive Normalizaing flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbc19a",
   "metadata": {},
   "source": [
    "<center><img src=\"pics/flows_how2.png\" width=800 /></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d2257",
   "metadata": {},
   "source": [
    "TODO: a few words about objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a0160",
   "metadata": {},
   "source": [
    "* $f = f_{K} \\circ f_{K - 1} \\circ \\dots \\circ f_1$. $f_{k}$, $f_k$ is some diffeomorphism\n",
    "\n",
    "* $f^{-1} = g = g_1 \\circ g_2 \\circ \\dots \\circ g_{K}$. $g_{k} = f_{k}^{-1}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9871512",
   "metadata": {},
   "source": [
    "For Gaussian Autoregressive NF $f_k$ and $g_k$ are expressed with the following formulas:\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        g_k: x_j &= \\sigma_j(x_{1:j-1}) z_j + \\mu_j(x_{1:j-1}), \\quad z_j \\sim N(0, 1)\\\\\n",
    "        f_k:      z_j &=  (x_j - \\mu_j(x_{1:j-1})) \\frac{1}{\\sigma_j(x_{1:j-1})}\n",
    "    \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f679f",
   "metadata": {},
   "source": [
    "$g_k$ is sequential, $f_k$ is not sequential.\n",
    "\n",
    "As a result we have 1) slow autoregressive sampling and 2) fast likelihood computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0716d237",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\begin{aligned}\n",
    "        f_k:      z_j &=  \\sigma_j(z_{1:j-1}) x_j + \\mu_j(z_{1:j-1}) \\\\\n",
    "        g_k: x_j &= (z_j - \\mu_j(z_{1:j-1})) \\frac{1}{\\sigma_j(z_{1:j-1})}, \\quad z_j \\sim N(0, 1)\n",
    "    \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f027ae",
   "metadata": {},
   "source": [
    "$g_k$ is not sequential, $f_k$ is sequential.\n",
    "\n",
    "As a result we have 1) fast sampling and 2) slow autoregressive likelihood computation.\n",
    "\n",
    "Moreover, now we have much slower training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a56b51f",
   "metadata": {},
   "source": [
    "So we would like to have a model without any of theese drawback, but still expressive enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c468b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RealNVP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7349bf8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For RealNVP $f_k$ and $g_k$ are expressed with the following formulas (both of them are not sequential):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a294a37",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"pics/RealNVPblock.png\" width=800 /></center>\n",
    "\n",
    "**Q:** How to model $\\boldsymbol{\\sigma}(\\cdot, \\theta)$ and $\\boldsymbol{\\mu}(\\cdot, \\theta)$ for $2D$ data case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6b49e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "# x : tensor (bs, 2) \n",
    "\n",
    "x_1 = x * mask # tensor (bs, 2), mask is [0, 1] or [1, 0]\n",
    "logit = NN(x_1) # tensor (bs, 2), i.e. NN : (bs, 2) -> (bs, 2)\n",
    "mu, log_sigma = logit.split # tensors (bs, 1), (bs, 1)\n",
    "# What to do next?\n",
    "mu = mu * (1 - mask)\n",
    "log_sigma = log_sigma * (1 - mask)\n",
    "z = log_sigma.exp() * x + mu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e08a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jacobian\n",
    "\n",
    "<center><img src=\"pics/RealNVPblock.png\" width=800 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49a1e57",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\log\\det \\left(\\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{x}}\\right) = \\log\\det \\begin{bmatrix}\\mathbf{I}_d & 0_{d \\times m - d}\\\\ \\frac{\\partial \\boldsymbol{z}_2}{\\partial \\boldsymbol{x}_1} & \\frac{\\partial \\boldsymbol{z}_2}{\\partial \\boldsymbol{x}_2} \\end{bmatrix} =\\\\= \\text{sum } [ \\underbrace{0, 0, \\dots 0}_{d \\text{ times}} ,  \\log \\frac{\\partial z_{d + 1}}{\\partial x_{d + 1}}, \\dots , \\log \\frac{\\partial z_{m}}{\\partial x_{m}}] = ?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42ca88",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Q:** What is RealNVP block input and output?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2292a3d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "# x : tensor (bs, 2) \n",
    "\n",
    "z, log_det = RealNVPBlock(x) # tensors (bs, 2), (bs, 2)\n",
    "```\n",
    "\n",
    "* `log_det` is the batch of vectors $[\\log \\frac{\\partial z_{1}}{\\partial x_{1}}, \\log \\frac{\\partial z_{2}}{\\partial x_{2}}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d4f6f8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Principial RealNVP block scheme (for both $2D$ data and image data)\n",
    "\n",
    "```python\n",
    "# x : tensor (bs, *shape)\n",
    "\n",
    "x_1 = prepare_x1(x)\n",
    "logit = NN(x_1)\n",
    "mu, log_sigma = logit.split\n",
    "z = coupling(mu, log_sigma, x) # z.shape == x.shape\n",
    "log_det = log_frac_dz_i_dx_i(mu, log_sigma, x) # log_det.shape == x.shape !!!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18118386",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Q:** How to combine several RealNVP blocks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d4c006",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "# x : tensor (bs, 2) \n",
    "\n",
    "# RealNVPBlockList = [RealNVPBlock(0), RealNVPBloc(1), ...]\n",
    "log_det = 0\n",
    "for i in range(N):\n",
    "    z, curr_log_det = RealNVPBlockList[i](x)\n",
    "    log_det += curr_log_det\n",
    "    x = z\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584276d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Q:** How to train RealNVP model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6029a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Use **ForwardKL** in the data $X$-space (or **ReverseKL** in the latent $Z$-space which is equivalent). Objective:\n",
    "\n",
    "$$-E_{\\pi(x)} \\left(\\log p_z(f(x, \\theta)) + \\log | \\det J_f|\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe087f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Q:** How to split data vector $\\boldsymbol{x}$ onto $[\\boldsymbol{x}_1, \\boldsymbol{x}_2]$ when $\\boldsymbol{x}$ is an image?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ceb339",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### RealNVP block for image data case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbcb48",
   "metadata": {},
   "source": [
    "The splitting schemes were proposed in the original RealNVP [article](https://arxiv.org/pdf/1605.08803.pdf).\n",
    "\n",
    "<center><img src=\"pics/image_splitting_realnvp.png\" width=800 /></center>\n",
    "\n",
    "**Question**: What does the picture show?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd8bfb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `CheckerboardCouplingLayer`\n",
    "\n",
    "<center><img src=\"pics/checkerboard_splitting.png\" width=400 /></center>\n",
    "\n",
    "**Q:** Let input $\\boldsymbol{x}$ has shape `(bs, c, w, h)`. \n",
    "\n",
    "What is the input and output of the network which produces $\\boldsymbol{\\mu}, \\boldsymbol{\\log \\sigma}$ (what tensors and of which shape)? \n",
    "\n",
    "What is the output of `CheckerboardCouplingLayer` (what tensors and of which shape)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c4759",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `ChannelCouplingLayer`\n",
    "\n",
    "<center><img src=\"pics/channelwise_splitting.png\" width=400 /></center>\n",
    "\n",
    "**Q:** Do we need to mask the input tensor $\\boldsymbol{x}$ in order to get $\\boldsymbol{x}_1$?\n",
    "\n",
    "**Q:** Let input $\\boldsymbol{x}$ has shape `(bs, 2 * c, w, h)`. \n",
    "\n",
    "What is the input and output of the network which produces $\\boldsymbol{\\mu}, \\boldsymbol{\\log \\sigma}$ (what tensors and of which shape)?\n",
    "\n",
    "What is the output of `ChannelCouplingLayer` (what tensors and of which shape)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d09488",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `squeeze` and `undo_squeeze` operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d544b05a",
   "metadata": {},
   "source": [
    "<center><img src=\"pics/squeezing.png\" width=600 /></center>\n",
    "\n",
    "**Q:** Let input $\\boldsymbol{x}$ has shape `(bs, c, w, h)`. Shape of the tensor under `squeeze` operation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8636186",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Expected ordering of Coupling layers**\n",
    "\n",
    "(following the original article [RealNVP](https://arxiv.org/pdf/1605.08803.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c5c70",
   "metadata": {},
   "source": [
    "```python\n",
    "#input: (bs, 1, w, h)\n",
    "CheckerboardCouplingLayer(\"even\"),\n",
    "CheckerboardCouplingLayer(\"odd\"),\n",
    "CheckerboardCouplingLayer(\"even\"),\n",
    "CheckerboardCouplingLayer(\"odd\"),\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7888bc3",
   "metadata": {},
   "source": [
    "```python\n",
    "# squeeze the tensor: (bs, 1, w, h) -> (bs, 4, w/2, h/2)\n",
    "squeeze()\n",
    "ChannelCouplingLayer(\"top\")\n",
    "ChannelCouplingLayer(\"bottom\")\n",
    "ChannelCouplingLayer(\"top\")\n",
    "ChannelCouplingLayer(\"bottom\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c983a27",
   "metadata": {},
   "source": [
    "```python\n",
    "# unsqueeze the tensor: (bs, 4, w/2, h/2) -> (bs, 1, w, h)\n",
    "unsqueeze()\n",
    "CheckerboardCouplingLayer(\"even\"),\n",
    "CheckerboardCouplingLayer(\"odd\"),\n",
    "CheckerboardCouplingLayer(\"even\"),\n",
    "CheckerboardCouplingLayer(\"odd\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
